{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install opencv-python-headless numpy pandas tensorflow keras matplotlib scikit-learn"
      ],
      "metadata": {
        "id": "Q_XVWJVjapXn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_K0GF5rqX_EH"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import os\n",
        "import cv2\n",
        "import shutil\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from keras import layers\n",
        "from google.colab import drive\n",
        "from keras.models import Model\n",
        "from keras import backend as K\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.preprocessing import image\n",
        "from keras.utils import to_categorical\n",
        "from keras.applications import ResNet50\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras.optimizers.legacy import Adam\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
        "from keras.layers import Input, Conv2D, Concatenate, UpSampling2D, Conv2DTranspose"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rSaywg8nY6n_"
      },
      "outputs": [],
      "source": [
        "# Helper functions for data processing\n",
        "def one_hot_encode(label, label_values):\n",
        "    semantic_map = []\n",
        "\n",
        "    # Convert grayscale to RGB if needed\n",
        "    if len(label.shape) == 2:\n",
        "        label = np.stack([label, label, label], axis=-1)\n",
        "\n",
        "    for colour in label_values:\n",
        "        equality = np.all(np.equal(label, colour), axis=-1)\n",
        "        semantic_map.append(equality)\n",
        "\n",
        "    semantic_map = np.stack(semantic_map, axis=-1)\n",
        "\n",
        "    return semantic_map.astype('float')\n",
        "\n",
        "def resize_mask(mask, target_size):\n",
        "    resized_mask = cv2.resize(mask, target_size, interpolation=cv2.INTER_NEAREST)\n",
        "    return resized_mask\n",
        "\n",
        "def reverse_one_hot(image):\n",
        "    x = np.argmax(image, axis=-1)\n",
        "    return x\n",
        "\n",
        "def colour_code_segmentation(image, label_values):\n",
        "    colour_codes = np.array(label_values)\n",
        "    x = colour_codes[image.astype(int)]\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tcz944ViY1dh"
      },
      "outputs": [],
      "source": [
        "# ResNet-based UNet model\n",
        "def build_resnet_unet(input_shape, num_classes):\n",
        "\n",
        "    # Input layer\n",
        "    input_tensor = Input(shape=input_shape)\n",
        "\n",
        "    # Load ResNet50 model\n",
        "    base_model = ResNet50(weights='imagenet', include_top=False, input_tensor=input_tensor)\n",
        "\n",
        "    # Freeze the layers in the base model\n",
        "    for layer in base_model.layers:\n",
        "        layer.trainable = False\n",
        "\n",
        "    # Intermediate layers from the base model\n",
        "    block1 = base_model.get_layer('conv1_relu').output\n",
        "    block2 = base_model.get_layer('conv2_block3_out').output\n",
        "    block3 = base_model.get_layer('conv3_block4_out').output\n",
        "    block4 = base_model.get_layer('conv4_block6_out').output\n",
        "\n",
        "    # Decoder\n",
        "    x = UpSampling2D(size=(2, 2))(block4)\n",
        "    x = Concatenate()([x, block3])\n",
        "    x = Conv2D(1024, (3, 3), padding='same', activation='relu')(x)\n",
        "    x = Conv2D(1024, (3, 3), padding='same', activation='relu')(x)\n",
        "\n",
        "    x = UpSampling2D(size=(2, 2))(x)\n",
        "    x = Concatenate()([x, block2])\n",
        "    x = Conv2D(512, (3, 3), padding='same', activation='relu')(x)\n",
        "    x = Conv2D(512, (3, 3), padding='same', activation='relu')(x)\n",
        "\n",
        "    x = UpSampling2D(size=(2, 2))(x)\n",
        "    x = Concatenate()([x, block1])\n",
        "    x = Conv2D(256, (3, 3), padding='same', activation='relu')(x)\n",
        "    x = Conv2D(256, (3, 3), padding='same', activation='relu')(x)\n",
        "\n",
        "    x = UpSampling2D(size=(2, 2))(x)\n",
        "    x = Conv2D(128, (3, 3), padding='same', activation='relu')(x)\n",
        "    x = Conv2D(128, (3, 3), padding='same', activation='relu')(x)\n",
        "\n",
        "\n",
        "    # Output layer with a variable number of filters based on num_classes\n",
        "    x = Conv2D(num_classes, (1, 1), activation='sigmoid')(x)\n",
        "\n",
        "    # Compile\n",
        "    model = Model(inputs=input_tensor, outputs=x)\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y9mQJwgTY5UB"
      },
      "outputs": [],
      "source": [
        "def data_generator(image_paths, mask_paths, batch_size, input_shape):\n",
        "    num_samples = len(image_paths)\n",
        "    indices = list(range(num_samples))\n",
        "\n",
        "    while True:\n",
        "        random.shuffle(indices)\n",
        "        for i in range(0, num_samples, batch_size):\n",
        "            batch_indices = indices[i:min(i + batch_size, num_samples)]\n",
        "            batch_images = []\n",
        "            batch_masks = []\n",
        "\n",
        "            for idx in batch_indices:\n",
        "                #random_zoom = random.random()\n",
        "                random_zoom = 0.01\n",
        "\n",
        "                img = cv2.imread(os.path.join(x_train_dir, image_paths[idx]), cv2.COLOR_BGR2RGB)\n",
        "                img = cv2.resize(img, (256, 256), fx = random_zoom, fy = random_zoom)\n",
        "                img = preprocess_input(img)\n",
        "\n",
        "                mask = cv2.imread(os.path.join(y_train_dir, mask_paths[idx]), cv2.COLOR_BGR2RGB)\n",
        "                mask = cv2.resize(mask, (256, 256), cv2.IMREAD_GRAYSCALE, fx = random_zoom, fy = random_zoom)\n",
        "\n",
        "                mask = one_hot_encode(mask, select_class_rgb_values).astype('float')\n",
        "\n",
        "                batch_images.append(img)\n",
        "                batch_masks.append(mask)\n",
        "\n",
        "            batch_masks = np.stack(batch_masks, axis=0)\n",
        "\n",
        "            yield np.array(batch_images), batch_masks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "48N1oznzZEre"
      },
      "outputs": [],
      "source": [
        "if __name__ == \"__main__\":\n",
        "\n",
        "    # ============================\n",
        "    # --------- CONFIG -----------\n",
        "    # ============================\n",
        "\n",
        "    # Mount Google Drive\n",
        "    drive.mount('/content/gdrive')\n",
        "\n",
        "    ROOT_DIR = ''                                # Root path\n",
        "    DATASET_DIR = os.path.join(ROOT_DIR, 'combined-dataset/tiff/')\n",
        "    LABEL_DICT_PATH = os.path.join(ROOT_DIR, 'combined-dataset/label_class_dict.csv')\n",
        "\n",
        "    # Model configuration\n",
        "    TF_LITE_MODEL_NAME = 'map_buildings.tflite'\n",
        "    SHOULD_TRAIN = False\n",
        "    INPUT_SHAPE = (256, 256, 3)\n",
        "\n",
        "    # Output folders\n",
        "    MODEL_CKPT_DIR = os.path.join(ROOT_DIR, 'output/model_checkpoints')\n",
        "    SAVED_MODEL_DIR = os.path.join(ROOT_DIR, 'output/saved_model')\n",
        "    INFERENCE_OUTPUT_DIR = os.path.join(ROOT_DIR, 'output/inference_images')\n",
        "\n",
        "    # Dataset folders\n",
        "    TRAIN_IMG_DIR = os.path.join(DATASET_DIR, 'train')\n",
        "    TRAIN_MASK_DIR = os.path.join(DATASET_DIR, 'train_labels')\n",
        "\n",
        "    VAL_IMG_DIR = os.path.join(DATASET_DIR, 'val')\n",
        "    VAL_MASK_DIR = os.path.join(DATASET_DIR, 'val_labels')\n",
        "\n",
        "    TEST_IMG_DIR = os.path.join(DATASET_DIR, 'test')\n",
        "    TEST_MASK_DIR = os.path.join(DATASET_DIR, 'test_labels')\n",
        "\n",
        "    # ============================\n",
        "    # ----- LOAD CLASS INFO ------\n",
        "    # ============================\n",
        "\n",
        "    class_dict = pd.read_csv(LABEL_DICT_PATH)\n",
        "    class_names = class_dict['name'].tolist()\n",
        "    class_rgb_values = class_dict[['r', 'g', 'b']].values.tolist()\n",
        "\n",
        "    select_classes = ['building']\n",
        "    select_class_indices = [class_names.index(cls.lower()) for cls in select_classes]\n",
        "    select_class_rgb_values = np.array(class_rgb_values)[select_class_indices]\n",
        "    num_classes = len(select_classes)\n",
        "\n",
        "    # ============================\n",
        "    # ----- TRAIN/VAL/TEST SPLIT -\n",
        "    # ============================\n",
        "\n",
        "    train_image_paths = sorted(os.listdir(TRAIN_IMG_DIR))\n",
        "    train_mask_paths = sorted(os.listdir(TRAIN_MASK_DIR))\n",
        "\n",
        "    train_image_paths, val_image_paths, train_mask_paths, val_mask_paths = train_test_split(\n",
        "        train_image_paths, train_mask_paths, test_size=0.2\n",
        "    )\n",
        "\n",
        "    val_image_paths, test_image_paths, val_mask_paths, test_mask_paths = train_test_split(\n",
        "        val_image_paths, val_mask_paths, test_size=0.5\n",
        "    )\n",
        "\n",
        "    # ============================\n",
        "    # ---- DATA GENERATORS -------\n",
        "    # ============================\n",
        "\n",
        "    batch_size = 4\n",
        "    steps_per_epoch = len(train_image_paths) // batch_size\n",
        "    validation_steps = len(val_image_paths) // batch_size\n",
        "\n",
        "    train_generator = data_generator(train_image_paths, train_mask_paths, batch_size, INPUT_SHAPE)\n",
        "    val_generator = data_generator(val_image_paths, val_mask_paths, batch_size, INPUT_SHAPE)\n",
        "\n",
        "    # ============================\n",
        "    # ----- CHECKPOINT SETUP -----\n",
        "    # ============================\n",
        "\n",
        "    checkpoint_path = os.path.join(MODEL_CKPT_DIR, 'cp-{epoch:04d}.ckpt')\n",
        "    model_callback = ModelCheckpoint(\n",
        "        checkpoint_path,\n",
        "        save_weights_only=True,\n",
        "        save_best_only=True,\n",
        "        verbose=1\n",
        "    )\n",
        "\n",
        "    # ============================\n",
        "    # ----- MODEL LOADING --------\n",
        "    # ============================\n",
        "\n",
        "    checkpoint_files = [f for f in os.listdir(MODEL_CKPT_DIR) if 'ckpt.' in f]\n",
        "\n",
        "    if checkpoint_files:\n",
        "        checkpoint_file_path = os.path.join(MODEL_CKPT_DIR, 'checkpoint')\n",
        "\n",
        "        with open(checkpoint_file_path, 'r') as f:\n",
        "            latest_checkpoint_info = f.readline().strip()\n",
        "\n",
        "        latest_checkpoint_basename = re.search(r'model_checkpoint_path: \"([^\"]+)\"',\n",
        "                                               latest_checkpoint_info).group(1)\n",
        "\n",
        "        latest_checkpoint_path = os.path.join(MODEL_CKPT_DIR, latest_checkpoint_basename)\n",
        "\n",
        "        model = build_resnet_unet(INPUT_SHAPE, num_classes)\n",
        "        model.load_weights(latest_checkpoint_path)\n",
        "        model.compile(optimizer=Adam(1e-4), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "        print(f\"Loaded weights from checkpoint: {latest_checkpoint_path}\")\n",
        "\n",
        "    elif os.path.exists(SAVED_MODEL_DIR):\n",
        "        model = tf.keras.models.load_model(SAVED_MODEL_DIR)\n",
        "        print(\"Loaded full TensorFlow SavedModel\")\n",
        "\n",
        "    else:\n",
        "        model = build_resnet_unet(INPUT_SHAPE, num_classes)\n",
        "        model.compile(optimizer=Adam(1e-4), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "        print(\"Training new model...\")\n",
        "\n",
        "    # ============================\n",
        "    # -------- TRAINING ----------\n",
        "    # ============================\n",
        "\n",
        "    if SHOULD_TRAIN:\n",
        "        history = model.fit(\n",
        "            train_generator,\n",
        "            steps_per_epoch=steps_per_epoch,\n",
        "            validation_data=val_generator,\n",
        "            validation_steps=validation_steps,\n",
        "            epochs=50,\n",
        "            callbacks=[model_callback]\n",
        "        )\n",
        "\n",
        "        # Save TF SavedModel\n",
        "        model.save(SAVED_MODEL_DIR)\n",
        "\n",
        "        # Convert to TFLite\n",
        "        converter = tf.lite.TFLiteConverter.from_saved_model(SAVED_MODEL_DIR)\n",
        "        tflite_model = converter.convert()\n",
        "\n",
        "        # Save TFLite model\n",
        "        tflite_path = os.path.join(ROOT_DIR, 'output', TF_LITE_MODEL_NAME)\n",
        "        with open(tflite_path, 'wb') as f:\n",
        "            f.write(tflite_model)\n",
        "\n",
        "        print(f\"Saved TensorFlow Lite model: {tflite_path}\")\n",
        "\n",
        "    # ============================\n",
        "    # -------- EVALUATION --------\n",
        "    # ============================\n",
        "\n",
        "    test_generator = data_generator(test_image_paths, test_mask_paths, batch_size, INPUT_SHAPE)\n",
        "    test_steps = len(test_image_paths) // batch_size\n",
        "\n",
        "    test_loss, test_accuracy = model.evaluate(test_generator, steps=test_steps)\n",
        "    print(f\"Test Loss: {test_loss:.4f}\")\n",
        "    print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
        "\n",
        "    # ============================\n",
        "    # -------- INFERENCE ---------\n",
        "    # ============================\n",
        "\n",
        "    os.makedirs(INFERENCE_OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "    for idx, (image_batch, mask_batch) in enumerate(test_generator):\n",
        "        if idx >= test_steps:\n",
        "            break\n",
        "\n",
        "        predicted_masks_batch = model.predict(image_batch)\n",
        "\n",
        "        for i in range(len(image_batch)):\n",
        "            original_image = image_batch[i]\n",
        "            true_mask = mask_batch[i]\n",
        "            predicted_mask = (predicted_masks_batch[i] > 0.5).astype(float)\n",
        "\n",
        "            plt.figure(figsize=(12, 4))\n",
        "\n",
        "            plt.subplot(1, 3, 1)\n",
        "            plt.imshow(original_image)\n",
        "            plt.title('Image')\n",
        "            plt.axis('off')\n",
        "\n",
        "            plt.subplot(1, 3, 2)\n",
        "            plt.imshow(true_mask.squeeze(), cmap='gray')\n",
        "            plt.title('Ground Truth')\n",
        "            plt.axis('off')\n",
        "\n",
        "            plt.subplot(1, 3, 3)\n",
        "            plt.imshow(predicted_mask.squeeze(), cmap='gray')\n",
        "            plt.title('Predicted')\n",
        "            plt.axis('off')\n",
        "\n",
        "            result_path = os.path.join(INFERENCE_OUTPUT_DIR, f'result_{idx}_{i}.png')\n",
        "            plt.savefig(result_path)\n",
        "            plt.close()\n",
        "\n",
        "        print(f\"Inference images saved in: {INFERENCE_OUTPUT_DIR}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}